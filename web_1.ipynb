{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Includes all the necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium_manager\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_manger\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# from selenium_manager import WebDriverWait\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/Python/Web-scraping/selenium_manager.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# options.add_argument(\"headless\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m options\u001b[39m.\u001b[39madd_argument(\u001b[39m\"\u001b[39m\u001b[39m--disable-gpu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(\n\u001b[1;32m     21\u001b[0m     executable_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/$\u001b[39;49m\u001b[39m{userName}\u001b[39;49;00m\u001b[39m/Drivers/chromedriver\u001b[39;49m\u001b[39m'\u001b[39;49m, chrome_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "# Includes all the necessary libraries\n",
    "from selenium_manager import *\n",
    "from data_manger import *\n",
    "# from selenium_manager import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'London'\n",
    "job_title = 'data+scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web link of page\n",
    "url = f'https://uk.indeed.com/jobs?q={job_title}&l={location}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_handle(url):\n",
    "    # Create chrome web driver objects\n",
    "    driver = webdriver.Chrome()\n",
    "    \"\"\"Get's the url and post \n",
    "    data the webdriver\"\"\"\n",
    "    driver.get(url)\n",
    "    # Clears the cookies pop-up\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//button[text()=\"Accept All Cookies\"]').click()\n",
    "    return driver\n",
    "\n",
    "\n",
    "def to_data_frame(data):\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Returns job roles\n",
    "\n",
    "\n",
    "def get_roles(driver):\n",
    "    titles = driver.find_elements(By.CLASS_NAME, \"jcs-JobTitle[href]\")\n",
    "    roles = []\n",
    "    for title in titles:\n",
    "        roles.append(title.text)\n",
    "    return roles\n",
    "\n",
    "# Returns Companies names\n",
    "\n",
    "\n",
    "def get_employers(driver):\n",
    "    employers = driver.find_elements(By.CLASS_NAME, 'companyName')\n",
    "    companies = []\n",
    "    for company in employers:\n",
    "        companies.append(company.text)\n",
    "    return companies\n",
    "\n",
    "# Returns job locations\n",
    "\n",
    "\n",
    "def get_location(driver):\n",
    "    job_locations = driver.find_elements(By.CLASS_NAME, 'companyLocation')\n",
    "    locations = []\n",
    "    for local in job_locations:\n",
    "        locations.append(local.text)\n",
    "    return locations\n",
    "\n",
    "# Returns job links\n",
    "\n",
    "\n",
    "def get_links(driver):\n",
    "    web_links = driver.find_elements(By.CLASS_NAME, 'jcs-JobTitle[href]')\n",
    "    links = []\n",
    "    for link in web_links:\n",
    "        links.append(link.get_attribute('href'))\n",
    "    return links\n",
    "\n",
    "\n",
    "# Returns salary info\n",
    "def get_salary(driver):\n",
    "    salary_info = driver.find_elements(\n",
    "        By.CLASS_NAME, 'salary-snippet-container')\n",
    "    salary = []\n",
    "    for sal in salary_info:\n",
    "        salary.append(sal.text)\n",
    "    return salary\n",
    "\n",
    "\n",
    "# Returns Job description\n",
    "def get_description(driver):\n",
    "    descriptions_info = driver.find_elements(By.CLASS_NAME, 'job-snippet')\n",
    "    descriptions = []\n",
    "    for description in descriptions_info:\n",
    "        descriptions.append(description.text)\n",
    "    return descriptions\n",
    "\n",
    "\n",
    "def page_iter(driver):\n",
    "    # Navigate to the next page\n",
    "    next_button_xpath = '//*[@id=\"jobsearch-JapanPage\"]/div/div/div[5]/div[1]/nav/div[7]/a'\n",
    "    driver.find_element(By.XPATH, next_button_xpath).click()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = client_handle(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from functions\n",
    "roles = get_roles(driver)\n",
    "companies = get_employers(driver)\n",
    "salary = get_salary(driver)\n",
    "locations = get_location(driver)\n",
    "links = get_links(driver)\n",
    "descriptions = get_description(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple data Series\n",
    "roles_series = pd.Series(roles)\n",
    "companies_series = pd.Series(companies)\n",
    "salary_series = pd.Series(salary)\n",
    "location_series = pd.Series(locations)\n",
    "links_series = pd.Series(links)\n",
    "descriptions_series = pd.Series(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Created dict for data Series\n",
    "job_postings = {'Roles': roles_series,\n",
    "                'Companies': companies_series,\n",
    "                'Salary': salary_series,\n",
    "                'Location': locations,\n",
    "                'Descriptions': descriptions_series,\n",
    "                'Links': links_series}\n",
    "# Creates data frame\n",
    "data = to_data_frame(job_postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates a csv with the collected data\n",
    "data.to_csv('today_list_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roles</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Cricket</td>\n",
       "      <td>Pythia Sports</td>\n",
       "      <td>£40,000 - £60,000 a year</td>\n",
       "      <td>London SW1V</td>\n",
       "      <td>Have a deep understanding of the data, its lim...</td>\n",
       "      <td>https://uk.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IO Sphere</td>\n",
       "      <td>Up to £29,706 a year</td>\n",
       "      <td>Hybrid remote in London</td>\n",
       "      <td>By the end, you will be an effective data scie...</td>\n",
       "      <td>https://uk.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VP of Data Science and Experimentation</td>\n",
       "      <td>Trustpilot</td>\n",
       "      <td>Up to £37,462 a year</td>\n",
       "      <td>London</td>\n",
       "      <td>Make analytical techniques approachable and un...</td>\n",
       "      <td>https://uk.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flood Risk Data Analyst Officer</td>\n",
       "      <td>Environment Agency</td>\n",
       "      <td>£500 - £540 a day</td>\n",
       "      <td>Hybrid remote in England</td>\n",
       "      <td>You will likely have a bachelor’s degree in da...</td>\n",
       "      <td>https://uk.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flood Risk Data Analyst Advisor</td>\n",
       "      <td>Environment Agency</td>\n",
       "      <td>£65,000 - £85,000 a year</td>\n",
       "      <td>Hybrid remote in England</td>\n",
       "      <td>You will likely have a bachelor’s degree in da...</td>\n",
       "      <td>https://uk.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Roles           Companies   \n",
       "0                Data Scientist - Cricket       Pythia Sports  \\\n",
       "1                          Data Scientist           IO Sphere   \n",
       "2  VP of Data Science and Experimentation          Trustpilot   \n",
       "3         Flood Risk Data Analyst Officer  Environment Agency   \n",
       "4         Flood Risk Data Analyst Advisor  Environment Agency   \n",
       "\n",
       "                     Salary                  Location   \n",
       "0  £40,000 - £60,000 a year               London SW1V  \\\n",
       "1      Up to £29,706 a year   Hybrid remote in London   \n",
       "2      Up to £37,462 a year                    London   \n",
       "3         £500 - £540 a day  Hybrid remote in England   \n",
       "4  £65,000 - £85,000 a year  Hybrid remote in England   \n",
       "\n",
       "                                        Descriptions   \n",
       "0  Have a deep understanding of the data, its lim...  \\\n",
       "1  By the end, you will be an effective data scie...   \n",
       "2  Make analytical techniques approachable and un...   \n",
       "3  You will likely have a bachelor’s degree in da...   \n",
       "4  You will likely have a bachelor’s degree in da...   \n",
       "\n",
       "                                               Links  \n",
       "0  https://uk.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
       "1  https://uk.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
       "2  https://uk.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
       "3  https://uk.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
       "4  https://uk.indeed.com/pagead/clk?mo=r&ad=-6NYl...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
